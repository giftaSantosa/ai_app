{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bab6975-1b8c-4952-bfea-225f64f4818f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gifta.santosa/venv/lib/python3.14/site-packages/langchain_core/_api/deprecation.py:26: UserWarning: Core Pydantic V1 functionality isn't compatible with Python 3.14 or greater.\n",
      "  from pydantic.v1.fields import FieldInfo as FieldInfoV1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama, also known as Open Language Modeling (OpenLlama), was a fork of Microsoft's Codex model that provided access to large language models like GPT-3. It allowed individuals or researchers without the need for advanced technical setup to interact with these powerful AI tools through an interactive terminal interface and API calls, primarily focusing on natural language processing tasks such as coding assistance, text completion, summarization, etc.\n",
      "\n",
      "OllamaLLM is not a widely recognized term in the context of Ollama or general artificial intelligence discussions; it seems to be either incorrectly mentioned or perhaps an obscure project that has been overshadowed by more prominent models like GPT-3 and Codex. It's possible that \"Ollama LL\" was intended as shorthand for something associated with enhanced versions of Ollama, such as custom fine-tuning using additional data specific to a userâ€™selffocused context (hence the 'LLM'). However, without further information on this term or project within publicly available AI resources up until my knowledge cutoff in 2024, there is no established difference between \"Ollama\" and what might be referred to as an Ollama LL. If you're looking for advanced customizations of the Codex model running via Ollama with language-specific adaptations (LLM), I would recommend consulting GitHub or similar repositories where developers often fork projects, including AI models like OpenLlama and provide detailed documentation on their extensions or modifications to these systems.\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "llm = OllamaLLM(model=\"phi3\")\n",
    "\n",
    "response = llm.invoke(\"What is the difference between Ollama and OllamaLLM?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06a0196-0813-44f3-8d1b-0aac16c3faf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (MyVenv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
